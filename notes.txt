
Fiducial tracking from NERVE cameras
	Camera uses RTSP
	Default TUIO tracker implementation can't use RTSP cameras
	v4l2loopback is broken on Ubuntu 14.04
		Yes, both v4l2loopback-dkms and v4l2loopback-source + module-helper
		Not going to bother compiling from source
			It would break with every kernel upgrade
			Unconvinced it's going to work, given that the packages are broken
		So no converting RTSP to a /dev/videoX entry
	TUIO isn't actually a fiducial library, it's a protocol
	And the reacTable amoeba tags appear to be detcted by a binary blob
		So those guys can go pound sand, I'll use something I can use. 
	April tags?


Bugs in v1 hardware:
Don't use 0204 parts. They're annoyingly tiny. 1206 for everything. 
The caps are OK 0805
The footprint for the diode is too big, it's only slightly bigger than 1206. 
The footprint for the switch needs the leg contacts moved in by half their length towards the switch
Via for the heat sink for the motor drivers needs to not be under the ESP8266
Connectorize battery

Needs pull-up to connect CH_PD high, pull-downs on GPIO15 (all times) and GPIO0 (only for programming)
 - GPIO15 is what I was going to use for one of the fault sensing lines

DRV8833 might be a good canidate for next driver, but only has PWM interface.
3A drive if outputs are paralleled, available in a TSSOP16 package. 

IFX9201SGAUMA1 would also be good, but requires higher voltage (e.g. two-cell battery and voltage regulation)
Has SPI interface, 6A(!) drive current, full bridge per chip. 
 
https://github.com/esp8266/Arduino/issues/22 Has how to get automatic reset, easier than integrating the limpkin.fr reset circuit.  
Needs a serial adapter that has DTR line, ordered that. 

Assembly pointers:
Get you some fine-point tweezers for great good

Ideological bugs:
Off is not where you think it is on the switch (on is towards the battery)
- Label on the PCB
Surface mount ESP8266 has no idiot lights, add one so I can tell when it is on
Add another light to an unused GPIO for debugging
Any reason I shouldn't have all pull-ups be one value (have some 10k and some 1k)?


Mobile Sensor Network Deployment using Potential Fields
Andrew Howard, Maja Mataric, Gaurav Sukhatme
	Deploying a sensor network in unknown environment
	Mobile nodes
	Maximize coverage
	Nodes are repelled by obstacles and each other
		Viscous friction force so that the expansion eventually stops
	No need for localization, aside from relative to other nodes
	Only does one thing (spread out)

A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation
Jakob Fredslund, Maja J Mataric	
N robots, form geometric shape
	Each robot picks a friend, makes sure that friend is at angle Theta
	Three principles of formation control
	Unit-center-referenced
		Relative to centroid of all robots
		Requires global knowledge
	Leader-referenced
		Position of a selected leader
	Neighbor-referenced
		Relative to position of nearest neighbor
		Uses local knowledge
	Paper cites a bunch of possible strategies for formations 
	One robot is leader, has no friends, decides heading of formation
	Certain formations cannot be formed
		Can have at most two loose ends
		Assumptions of sensor precent certain curves
	Angle robot needs to keep its friend at depends on rank in formation
		Allows different angles for e.g. squares
	Leader can drag whole formation around
	Includes algorithims for avoiding obstacles
	Includes handling of individual robot "termination"

Laser-Based People Tracking
Ajo Fod, Andrew Howard, Maja J Mataric
	Tracking people using plana laser scanners
	Objects are tracked as blobs
	Blobs are registered between frames
		Prediction and update steps
	Groups of blobs that stay together are objects
	Object tracker smooths object paths and compensates for occlusions
	From old frame to new frame
		Bounding box old objects
		Expand box
		Check for matches within the expanded box in the new frame
			Minimum-distance point pairs are "matches"
		Weghted by quality of match, which is number of point matches
		New blobs get a state vector of zero
		old blobs get parent's state vector
		State vector can continue to update predicted state of currently missing blobs
			So when they reappear near their predicted location, they get their old state vector

Detecting Anamalous Human Interactions using Laser Rangefinders
	Uses the system described in "Laser-Based People Tracking"
	Tracks of activities re segmented to maximise Jensen-Shannon divergence
	Comparing concurrent positions of tracks detects interactions
	Model of interactions in space is developed
		Anomalous interactions are those of low probability under the model
	

Challenges in Evolving Controllers for Physical Robots
Maja Mataric, Dave Cliff
	Evolves morphology and controller
	Genetic Programming
		Operates on lisp S-expressions as the genome
	Generally, evolutionary control takes a long time
	Generally, controllers are evolved to do exactly one task
	As of '96, no evolutionary controller was doing anything that couldn't be done by hand
	Realtime on real hardware 
		Battery life
		Wear on the robot
	Simulation
		Noise and error models
			Noise has to match real noise
				Otherwise, behavior won't transfer to real world
			GA can exploit abstractions in simulation
		Generality v. Utility
			Simulator that simulates a given robot well won't generalize
	Evaluation
		Detecting convergence is hard to automate
		Human ranking is tedious and slow
	Fitness functions
		Complex to design for complex cases
		Has the same exploitable abstraction problems as simulaton
		May not be able to measure fitness parameters (see Evaluation, above)
	Overall, it seems like this is a bad way to go about what I want

Minimizing Complexity in Controlling a Mobile Robot Population
Maja J Mataric
	Distrbuting a task over homogeneous robots
	Minimal Modeling and no planning
	Only covers tasks that can be done by a single robot
		but get better with multiple robots
		e.g. foraging
	Ignorant coexistance
		Robots treat each other as obstacles
		More robots leads to more problems, slower task completion
	Informed coexistance
		Robots behave differently when avoiding robots than obstacles
		Wait for the other robot to get out of the way, then evade
		Minimizes interference, better than ignorant case
	Intelligent coexistance
		Robots have an idea of local population density, population gradient
		Can minimize potential for interference, not just react to it
		Homing, flocking, etc. 

Design of the Army Ant Cooperative Lifting Robot
John S. Bay
	Not really related, more about mechanical and electronic design

Ant-inspired Navigation in Unknown Environments
	Combination of landmarks and transitions between them
	Failure to detect landmarks triggers search

Relaxation on a Mesh: a Formalism for Generalized Location
	Spring relaxation of networks including some globally localized bodies
	I don't plan to do global localization

Huey, Dewey, Louie, and GUI - Commanding Robot Formations
Jacob Fredslund, Maja j Mataric
	GUI for commanding robots into formations
	Only formation, no box pushing, patrolling, soda-can-collecting, etc. 
	Uses the formation algorithm from "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation"
	Gui specifies node locations, angles can be calculated from that
	Limitation remains that no robot can look behind itself for its friend


Robots in Formation Using Local Information
Jakob Fredslund, Maja J Mataric
	Same as "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation" but with more implementation details


Bounds of Neglect Benevolence in Input Timing for Human Interaction with Robot Swarms
Sasanka Nagavalli, Shih-Yi Chien et al
	User may need to make changes to the swarm's goal from a previous goal
	Two capabilities needed
		Comprehension of swarm state
			Relations and regularities in behavior
		Prediction of effect of input on state
			Human must develop a mental model of swarm responses
			Timing lags make this harder
	Adding the human input ASAP may not be optimal
		"Neglect Benevolence" - some neglect may be good
	How does human understand swarm dynamics to choose best time to intervene?
		Humans can learn to approximate optimal timing
	Paper refers to "Neglect Benevolence shape-changing HSI reference task"
	Doesn't really effect compilation or anything, but good for interface design


Human-Swarm Interaction: Sources of Uncertainty
Sean Hayes, Julie Adams
	Defines swarms as >= 50 entities	
	Multiple sources of Uncertainty
		Physical state uncertianty
			Position uncertainty - Where each of the robots is, relative position
			Motion uncertainty - keeping track of speed and direction of members
			Aggregation and subgroup
				Cohesion uncertainty - how well is subgroup bound?
		Virtual state uncertainty
			Leadership uncertainty - which units are leaders?
			Influence uncertainty - how much influence do leaders have?
		Compound state uncertainty - combined virtual and physical
			Goal outcome uncertainty - will individuals contribute to goal?
			Role uncertainty - units may change roles due to physical or virtual state
			Dominance - attempts to influence others that may fail

Explict vs. Tacit Leadership in influencing the Behavior of Swarms
Saman Amirpour Amraii
	How does a teleoperated leader influence the swarm?
		My swarm isn't going to do this
		May provide bottleneck/single point of failure
	Consensus (tacit)
		No leader/follower distinction
	Flooding (explict)
		Leader influence takes precedence
	May be useful for control design of the compiler
	Flooding generally converges faster



This is a scratch file that I put stuff in when I remove it from the main paper. 

Don't expect it to be useful, or even to contain complete sentences. 

Motion "primitives" from Stupid Robot Tricks
Motion $\rightarrow$ moveArc, moveStop, moveForward, moveByRemoteControl, bumpMove

Orientation $\rightarrow$ orientForOrbit, orbitRobot, orientToRobot, matchHeadingToRobot, followRobot

Navigation $\rightarrow$ followTheLeader, orbitGroup, navigateGradient

Clustering $\rightarrow$ clusterOnSource, clusterWithBreadCrumbs, clusterIntoGroups

Dispersion $\rightarrow$ avoidRobot, avoidManyRobots, disperseFromSource, disperseFromLeaves, disperseUniformly

Utility $\rightarrow$ detectEdges

detectEdges is "detect if you are on the edge of the swarm" 

Utility classes are to be regarded with skepticism, they are like "miscelaneous" categories. 

$\Rightarrow$ iRobot swarm had directional IR signaling (quadrants) using signal strength to figure out range and bearing, so that's something I'll want to include or emulate in my system. 

$\Rightarrow$ I should probably include some form of charging that doesn't involve a lot of hands-on interaction with my robots. 

Computer is aware of meaning of gesture, locations of robots. 
Second assumption (global localization) may not hold. 
How can computer determine what programs or what parameters result in the completion of the task?

What are the tasks? Assume search and rescue domain, what are the tasks in USR? Search an area with good coverage. Report content of an area. Group at a location. Locate a specific resource. 

This could be situated at an intersection between planning and compiling, as the compilation might have to factor in elements of the known environment at the time of compilation. Since the actors are spatially situated, plans should incorporate spatial awareness. 

$\Rightarrow$ Why is almost everyone ignoring power supplies except as an afterthought? Not a computer science problem?


Notes on papers in verification of swarm robotics

ALLIANCE: An Arcitecture for Fault Tolerant Multirobot Cooperation
	Distributed team is needed for distributed tasks
	Decomposing a problem adds complexity
	Fault tolerance is point failures (individual robots) or communication
		Can occur any time, must adapt
	2 kinds of cooperation
		Intentional/Explict cooperation
			ALLIANCE
		Swarm/Ant-like cooperation
			Other papers
			"Such approaches usually rely on mathematical convergence
			results (such as the random walk theorem [14]) that indicate
			the desired outcome over a sufficiently long period of time. A
			key research issue in this scenario is determining the proper
			design of the local control laws that will allow the collection
			of robots to solve a given problem." <- good pointer on what to look into
			Assumes homogeneous robot hardware & software
				Which I'm aiming to not have
	Distributed AI (DAI) is apparently a field
		Negotiation, which fails under no communication
		Tends to be agents with perfect communication, not fallible robots
		
	"Our assumptions are as follows.
	1) The robots on the team can detect the effect of their own
	actions, with some probability greater than 0.
	2) Robot can detect the actions of other team members
	has redundant capabilities, with some
	for which
	probability greater than 0; these actions may be de-
	tected through any available means, including explicit
	broadcast communication.
	3) Robots on the team do not lie and are not intentionally
	adversarial.
	4) The communications medium is not guaranteed to be
	available.
	5) The robots do not possess perfect sensors and effectors.
	6) Any of the robot subsystems can fail, with some prob-
	ability greater than 0.
	7) If a robot fails, it cannot necessarily communicate its
	failure to its teammates.
	8) A centralized store of complete world knowledge is not
	available."
		Good list, I should probably have a similar one for my paper, early in the problem description
	Paper points out that recognizing that something is happening is really hard
		Overhead cam can fake this sense, but that's a bad thing to rely on
	ALLIANCE overview
		Robots have behaviors
		Behaviors have motivations
		Motivations can activate or deactivate behaviors based on percieved need
		Some low level stuff (avoid obstacles) may not ever turn off (always needed)
		Only does one thing at a time (except the low-level stuff)
		Impatience
			Increases desire to perform a behavior, when seeing that it needs doing and other robots are failing
		Acquiesence 
			Decreases desire to perform a behavior, to avoid all robots trying to do the same thing
			Triggered by getting a message from another bot saying "chill, I got this"
		Could communicate "I'm currently doing X" with local comms, and remember previously seen robots that were doing a thing
			Sounds like a job for quorum sensing
			"I've seen robot M, it was doing X" replications (and a timeout "Last time I saw M...")
		Robots can detect that their behaviors fail
			And then become reluctant to use them again
	Subsumption provides a pretty good way of composing behaviors
		The behaviors can then be reasoned about using e.g. random walk theories or the stochastic stuff from GCPR	
		
Self-stabilizing Systems in Spite of Distributed Control (Dijkstra! He has a way with titles.)			
	Assumes a Legitimate State, and machines on a sparse connected graph
	Global awareness of legitimacy is hard
		Perhaps "locally legit" is good, as long as moves tend to spread legitimacy rather than illegitimacy
	Assumption of connectivity may not hold, but how does it extend to severing/merging graphs?
	
Decentralized Model Predictive Control of Cooperating UAVs (Arthur Richards and Jonathan How)
	Assumes solid communication
	has better performance than a centralized version of the algorithim
	Can operate as an anytime algorithim, so only computes what is needed
	
Decentralized Task Allocation for Dynamic Environments (Luke B. Johnson, MS Thesis)
	Broadcast messages
	Message count should be minimized
	Sequential greedy algorithim
		All agents assemble a bid, and shares it with all others
		Whichever agent feels it can do a task best (max score based on its own knowledge) wins the bid
		Constraints based on interdependant tasks, whether the agents can actually be trusted to do the job
			Is this anything like the blockchain? Could the blockchain be used for this?
		Reaching a synchronized state with incomplete communication may be very slow or impossible. 
	Consensus-Based Bundle Algorithm (CBBA)	
		Each agent creates a bundle of tasks
		Tasks are added if the agent can outbid the current high bid
		Some additions may conflict (multiple agents may have better scores than current high bid)
		Conflicts resoved by communication to see if anyone outbids
			If so, agent must release task and ALL SUBSEQUENT tasks (tasks are on a path, and so have dependencies)
		So agents build a bundle, lose all, some, or none of it, then rebid from the end of whatever is left
	Asynchronous Consensus Based Bundle Algorithm
		Allows agents to enter and leave network
	This whole paper isn't really about task completion, just assignment	
	
------ 7/10/17 -----

Had some concerns about thesis once it was framed as a planning problem rather than a compilation problem due to the fact that planning has a long history, and a lot of work already done in it. 

As a planning problem, user input is desired world state (or can be transformed to desired world state). 

Can possibly converge to desired world state without knowing starting state, as in stochastic box-pushing example on wiki. 

Planner with unknown worldstate is using "coercion" to make the world match a known state before or in the process of operating. 

UI may convey how precisely user's input is supposed to be followed. 
  - Direct line to end point just means "go here", indirect, bendy line means follow this exact path
  - Do we need to get close, vs. jsut approximately hit the target? How approximately?

Could need a hierarchy of subplans based on what's available to the compiler, in terms of robot abilities
  - Heterogenous "processors" for a parallel compilation task. 

Program generation for swarms? Looking into Carlo Pinciroli's stuff

Do any systems allow specification of the desired end state of the universe, not the actions to take? Can the actions be transformed into the target end state, i.e. how do you know you're done?

Grammatical Swarm: The generation of programs by social programming
  Particle Swarm Optimization
  Each particle is a choice of program constuction rule
  Rules are in BNF
  Based on Grammatical Evolution
  Sort of a genetic algorithm, but the evaluation function/fitness adds or removes velocity to the particle swarm
  So all the particles converge towards the best solution found so far, but explore around it
  Genotype specifies a BNF grammar that permits derivation of a program
  Still has the problem that the encoding of the fitness function becomes the iterative target rather than the actual code of the solution. 

Property-driven design for swarm robotics
Manuele Brambilla, Carlo Pinciroli, Mauro Birattari and Marco Dorigo
  Top-down design, as opposed to code-and-fix
    Code and fix is expertise-dependent
  Formal spec of desired properties (but of the system, not of system + world (what I'm calling "the universe"))
  Applied using Discrete time Markov chains and probablistic computation tree logic
    Oh god more stuff to learn
  Protoswarm
    Assumes constant network connectivity and total spatial coverage
  Hamiltonian Vector Field methods
  	Specification of the system is as energy potentials and flows
  	Only works for spatially-organizing behaviors
  Automatic design methods
  	Evolutionary and reinforcement methods
  	Domain knowledge required, result may not be verifiable or generalizable
  Property Verification
  	The turing tarpit of formalisms, where you can prove you can do things, but not actually do them
  	Scaling issues

  Property-driven Design
  	1. Specify properties
  	2. Build a model
  		Programmer iterates on the model, checking that properties are verified
  		Final model 
  	3. Model is used as a guide to implement the swarm software
  	4. Run it on some real robots. May need some tuning. 

  So this is a design method, not an end-to-end automation, still has developer iterating on something
  I want to not have a designer, and leave the iterating to computers

  PCTL expands a Markov chain into a (potentially infinite) tree rooted at the initial state
    CTL can make assertions like "a given state will be reached" or "a given state will hold for a fixed time"
    PCTL adds probabilities to those assertions
    Potentially infinite trees? Put that in your limited system memory and smoke it. 

  PRISM model checker implements PCTL and DTMC (among others)

  Case study on aggregation
    Allows time bounds on behavior, so none of my "converges in ... finite time, I hope"
    Behaviors still hand-designed by the programmer, so while it can be checked fast, it still needs to be written by a person
      My stuff would be automatically designing the behaviors or behavior sets and triggers

  Property-driven design reduces the probability of designing the "wrong" system, but doesn't let you not design the system


Boolean Network Robotics as an Intermediate Step in the Synthesis of Finite State Machines for Robot Control
Lorenzo Garattoni 1 , Andrea Roli 2 , Matteo Amaducci 2 , Carlo Pinciroli 1 and Mauro Birattari 1
  Automated design of compact high-level representations of control software for robots
  Larger exploration footprint for automated design methods, compared to manual
  Automated design of FSMs for controlling the robots
  Boolean Network robots?
    Boolean network is a model of genetic regulatory networks
      I wonder if this relates to guards in GCPR?
        It sure looks like it
        Oriented graph with N nodes, associated with a boolean value and boolean function of inputs to node
        Various update schemes
        To control a robot, some nodes are input and output nodes
        Input node boolean values are imposed by sensor precepts, not other nodes
        Output nodes control robot actions (motor vel, etc. or actions)
        Yeah, this smells like an isomorphism. 
    Can be analysed as dynamic systems
    Automatic design shapes network dynamics in limited areas of state space
    State clusters are associated with behaviors of the robot
    Map from clusters to FSM states to get a formal and explainable framework

  Calls out the existing problems with evolutionary controllers
    Have to constrain FSM size or you get really hairy, uncompact representations
  ANNs have problems with explainability

  Example programs use a constrained network size. 
  Rather than having all the nodes of the network be behavioral primitives, and sequences of boolean actions control those, the boolean network acts as an action selector. 
  Constant connectivity, intially random, three incoming inputs to each node. No self-connections.
  Flips bits at random in the boolean functions of the nodes, and only keeps the ones that work at least as well as the current best. 
  I bet boolean networks are stupid-fast and compact to represent in programmable hardware. 

  This case isn't specifying the desired behavior from a user input
  It also requires a lot of simulated runs to develop the working networks
    It's stochastic gradient descent operating on a binary genome, or evolution again. 
    No crossover, though. Probably for the best, that would transplant part of the FSM into another part. 

  Constrained to dealing with booleans
    Not really that much of a constraint, you can represent floats with booleans, at a (probably high) cost in complexity. 
    Evolving sub-modules might help reduce this, since a subnetwork can be reduced to a boolean network node itself. 


Finite State Automata Synthesis in Boolean Network Robotics
L. Garattoni, C. Pinciroli, A. Roli, M. Amaducci, and M. Birattari
  Still an evolutionary method, still needs a fitness function defined for it
  Also all the examples are for single-robot cases, no assumptions about interaction
    Binary robots could have senses for other robots, and at some levels of abstraction, quorum sensing
  Does permit dynamic behaviors, and so dynamic environment and systems
  "FSA asan indirect product of the design process of BN-robot systems and, hence, we
do not have the problems of representing automata in terms of genomes and
constraints."
    No, you represent it in terms of a binary string that evolves under control of a fitness function, though...

Recent Advances in AI Planning
Daniel S. Weld
  1999, talking about the last 5 years in planning 
  2-phase GRAPHPLAN
    Apparently very fast
    Detail level is a bit out of scope for my work at present, seems to cover the textbook sections I read
  Compiling planning problems into propostional formulas using SAT algorithms
  Talks about planning based on a known inital position of the world
  Calls out problems with universal quantifiers 

A Survey of the Seventh International Planning Competition
Amanda Coles, Andrew Coles, Angel García Olaya, Sergio Jiménez, Carlos Linares López, Scott Sanner, Sungwook Yoon
  Constrained planning domain description language (PDDL)
  Fixed domains, so people are running with a specific description of a specific domain
  various constraints in various tracks (optimality, uncertainty, etc.)
  Paper doesn't cover how things worked aside from what won and what techniques they were using


What I'm doing isn't exactly classical planning, because it's the generation of behaviors and the conditions under which they are to be executed, rather than a sequence of actions. No temporality in my "plan". Also, I don't assume that once all the behaviors have been executed, the desired world state holds. Instead, execution of at least some of the behaviors by at least some of the agents is intended to converge to the desired world state, but some behaviors may not be executed by some agents, and some agents may execute no behaviors (because they're broken). 

While we're talking weirdness, any binary sequence could be a representation of a binary network's binary functions, and so e.g. the complete works of Shakespear in ASCII, combined with a given connectivity, might do something cool.

SWARMORPH-script: a language for arbitrary morphology generation in self-assembling robots
Anders Lyhne Christensen, Rehan O’Grady, Marco Dorigo
  Governs self-assembling robots
  Morphology scripting, inter-robot lcoal communication

AutoMoDe-Chocolate: a Method for the Automatic Design of Robot Swarms that Outperforms Humans
G. Francesca
   Previous methods: Vanilla and EvoStick
   Vanilla beats EvoStick, humans beat all
   Chocolate = Vanilla + better optimization algorithm
   Design of collective behavior, but designer eventually has to specify the behavior of individual robots
   "Presently, no general approach exists to derive the individual behavior of the robots from a desired collective behavior"
      Well, that's encouraging to me...
   1. Specification
   2. Development using simulation
   3. Deployment onto a swarm
   AutoMoDe (2014) defines a program by composing probablistic FSMs
   Vanilla specializes AutoMoDe for the E-puck
      Shouldn't define the problem for specific homogeneous collections of robots
   Comparison with Vanilla and Evostick was on aggregation and foraging
      I'm assuming that things like aggregation were defined as primitives I can compose
      Foraging is a "find the box/target area" kind of thing, one step in performing a task
      So I think I'm looking at a level up from this
   5 methods on 5 tasks
      Fixed tasks, rather than open tasks as defined by the user
   Mentions work on task allocation via reaction-diffusion
      Works well with local state, so robots who are well-situated to solve a problem volunteer for it
      The idea of volunteering based on local information is probably a good way to look at it, in opposition to assignment by a central authority. 
   4 design methods
      Vanilla
         Assembles pre-exising modules into a PFSM
         Modules might have some parameters that affect their functioning
         Behaviors 
            Activity the robot can perform
         Transitions
            Control switching behaviors based on a condition or event
            Boolean, based on input values
         "The six behaviors are:
exploration, stop, phototaxis, anti-phototaxis, attraction, and repulsion. With the
exception of stop, these behaviors include an obstacle avoidance mechanism. The
six transitions are: black-floor, gray-floor, white-floor, neighbor-count, inverted-
neighbor-count, fixed-probability."
         Up to four states with up to four outgoing edges
         Optimize the expected value of a task-specific performance measure
         F-Race optimization algorithim, whoever does the task fastest is fittest
            Chocolate uses iterated F-Race
                Each iteration resamples search space with a distribution that favors the best performers on previous iterations
                This is starting to sound a lot like an evolutionary method
      EvoStick
         Evolutional method, generates feed-fwd ANN with no hidden nodes
         Inputs are robot sensors
         Outputs operate on the wheel speeds
            So the only possible actions are changing the position of the robot
      U-human
      	 Unconstrained human
      	 Person writing some code, no constraint on what they write
      	 Testing in ARGoS, but not the robots, like the automatic methods
      	 C++ class that operates on the inputs of the robot and provides logic for controlling the robot
      C-human
         Human who has to use the Vanilla control architecture and modules
         Human does what the Vanilla optimization algorithm would have to do
            This sounds like setting the human up for a beating, simply because they can't search the space as fast
         Again, only four states and at most four transitions out of each one
   5 conditions
      Shelter with constrained access
      Largest covering network
      Coverage with forbidden areas
      Surface and perimeter coverage
      Aggregation with ambient cues
         These are more complex tasks than my primitives, and possibly more complex than my tasks for the UI
   Vanilla and EvoStick can create solutions in 2h20m, so humans were given 4h, since they have to watch sims, and the software doesn't. 
   EvoStick beats the heck out of everything, all the time... in simulation
      It can't cross the reality gap, so it's probably overfitting
      In reality, it gets beat nearly all the time by something
   C-human beats U-human, which is surprising, but may be up to reduced variance due to reduced chance for bugs
   Chocolate beats humans, more in simulation than in reality, but usually in both
      Chocolate also has good reality-gap-crossing results

AutoMoDe-Chocolate: automatic design of control software for robot swarms
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, F. Mascia, V. Trianni , and M. Birattari
   Seems largely like a restating of the previous paper? Maybe that was a preprint. 

An Experiment in Automatic Design of Robot Swarms: AutoMoDe-Vanilla, EvoStick, and Human Experts
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, V. Trianni, M. Birattari
   14-page version of the two papers above

Boolean network robotics: a proof of concept
Andrea Roli and Mattia Manfroni, Carlo Pinciroli and Mauro Birattari
   Covers a lot of the same ground that the previous binary network paper I listed covers. 
   More mathematical explanation of the error/fitness function
   The evaluation heuristic from iterated F-Race sounds like it would be great for this
      Assuming that more-similar bitstrings have more-similar behavior, then selecting from a distribution that favors the elite examples would tend to generate more elite examples. 
   The single-bit-flip approach that was used is pretty close to this anyway, as it uses minimal perturbations
   Detail on training, used a shaping approach, where first phototaxis was trained, and then a handclap triggered antiphototaxis
      Longer runtime with the clap
   

ARK: Augmented Reality for Kilobots
Andreagiovanni Reina, Alex J. Cope, Eleftherios Nikolaidis, James A.R. Marshall, and Chelsea Sabo
   Similar design to my system
   Automates some aspects of e.g. identifying the robots
   Highly tied to the Kilobot platform
   I should certainly cite it, though



Things to look into: 
Multi-objectivization (Trianni and Lopes-Ibanez, 2014) 
Novelty Search (Lehman and Stanley 2011, Gomes et al 2013)
Heirarchical decomposition (Duarte et al, 2014) 
   Apparently untested on robots, and the decomposition is designed for the task by the programmer